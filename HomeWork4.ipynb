{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from kaggle_environments import make, evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляем агентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Только камень\n",
    "def rock_agent(observation, configuration):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Только бумага\n",
    "def paper_agent(observation, configuration):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Только ножницы\n",
    "def scissors_agent(observation, configuration):\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Повторение за оппонентом\n",
    "def copy_opponent(observation, configuration):\n",
    "    if observation.step > 0:\n",
    "        return observation.lastOpponentAction\n",
    "    else:\n",
    "        return random.randrange(0, configuration.signs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Случайное действие   \n",
    "def random_agent(observation, configuration):\n",
    "    return random.randint(0, configuration.signs - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Предсказание хода соперника\n",
    "def counter_opponent(observation, configuration):\n",
    "    if observation.step > 0:\n",
    "        return (observation.lastOpponentAction + 1) % configuration.signs\n",
    "    else:\n",
    "        return random.randrange(0, configuration.signs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Анализ предыдущих ходов соперника\n",
    "def pattern_matching_agent(observation, configuration, history = []):\n",
    "    if observation.step > 0:\n",
    "        history.append(observation.lastOpponentAction)\n",
    "    if len(history) > 3:\n",
    "        pattern = history[-3: ]\n",
    "        prediction = max(set(pattern), key = pattern.count)\n",
    "        return (prediction + 1) % configuration.signs\n",
    "    else:\n",
    "        return random.randrange(0, configuration.signs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Копирование выигрышных ходов соперника\n",
    "def tit_for_tat(observation, configuration):\n",
    "    if observation.step == 0:\n",
    "        return random.randrange(0, configuration.signs - 1)\n",
    "    else:\n",
    "        return observation.lastOpponentAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Использование неэффективной стратегии\n",
    "def anti_pattern_agent(observation, configuration, history=[]):\n",
    "    if observation.step > 0:\n",
    "        history.append(observation.lastOpponentAction)\n",
    "    if len(history) > 3:\n",
    "        prediction = max(set(history), key = history.count)\n",
    "        return (prediction + 2) % configuration.signs\n",
    "    else:\n",
    "        random.randint(0, configuration.signs - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Случайные значения с весом\n",
    "def weighted_random_agent(observation, configuration):\n",
    "    weights = [0.4, 0.3, 0.3]\n",
    "    return random.choices(range(configuration.signs), weights)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Адапптация под победные ходы соперника\n",
    "def reinforcement_learning_agent(observation, configuration, score=[0, 0, 0]):\n",
    "    if observation.step > 0:\n",
    "        score[observation.lastOpponentAction] += 1\n",
    "    return (score.index(max(score)) + 1) % configuration.signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ходы по порядку\n",
    "def cycle_agent(observation, configuration):\n",
    "    return observation.step % configuration.signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Противоположный выбор предыдущему ходу соперника\n",
    "def mirror_agent(observation, configuration):\n",
    "    if observation.step == 0:\n",
    "        return random.randint(0, configuration.signs - 1)\n",
    "    else:\n",
    "        return (observation.lastOpponentAction + 2) % configuration.signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Добавляем всех агентов в словарь\n",
    "agents = {\n",
    "    \"Rock Agent\": rock_agent,\n",
    "    \"Paper Agent\": paper_agent,\n",
    "    \"Scissors Agent\": scissors_agent,\n",
    "    \"Copy Opponent\": copy_opponent,\n",
    "    \"Random Agent\": random_agent,\n",
    "    \"Conter Opponent\": counter_opponent,\n",
    "    \"Patetrn Matching\": pattern_matching_agent,\n",
    "    \"Tit for tat\": tit_for_tat,\n",
    "    \"Anti Pattern\": anti_pattern_agent,\n",
    "    \"Weighted Random\": weighted_random_agent,\n",
    "    \"Reinforcement Learning\": reinforcement_learning_agent,\n",
    "    \"Cycle\": cycle_agent,\n",
    "    \"Mirror\": mirror_agent\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "Patetrn Matching: 19.5 points\n",
      "Conter Opponent: 18.0 points\n",
      "Cycle: 12.5 points\n",
      "Anti Pattern: 12.0 points\n",
      "Reinforcement Learning: 12.0 points\n",
      "Rock Agent: 11.5 points\n",
      "Tit for tat: 11.5 points\n",
      "Paper Agent: 11.0 points\n",
      "Scissors Agent: 11.0 points\n",
      "Weighted Random: 11.0 points\n",
      "Copy Opponent: 9.5 points\n",
      "Random Agent: 9.5 points\n",
      "Mirror: 7.0 points\n",
      "The best strategy is: Patetrn Matching\n"
     ]
    }
   ],
   "source": [
    "scores = {agent: 0 for agent in agents}\n",
    "results = {}\n",
    "\n",
    "#Турнир между агентами\n",
    "for agent_name_1, agent_1 in agents.items():\n",
    "    for agent_name_2, agent_2 in agents.items():\n",
    "        if agent_name_1 != agent_name_2:\n",
    "            score = evaluate(\n",
    "                \"rps\",\n",
    "                [agent_1, agent_2],\n",
    "                configuration={\"episodeSteps\": 1000}\n",
    "            )\n",
    "            # Средний результат первой стратегии против второй\n",
    "            average_score = sum([s[0] for s in score]) / len(score)\n",
    "            results[(agent_name_1, agent_name_2)] = average_score\n",
    "            #Определение победителя\n",
    "            if average_score > 0:\n",
    "                scores[agent_name_1] += 1  # Победа agent1\n",
    "            elif average_score < 0:\n",
    "                scores[agent_name_2] += 1  # Победа agent2\n",
    "            else:\n",
    "                scores[agent_name_1] += 0.5  # Ничья\n",
    "                scores[agent_name_2] += 0.5\n",
    "\n",
    "#Сортировка агентов по количеству очков\n",
    "sortred_results = sorted(scores.items(), key = lambda x: x[1], reverse=True)\n",
    "print(\"Results:\")\n",
    "for agent, score in sortred_results:\n",
    "    print(f'{agent}: {score} points')\n",
    "\n",
    "#Определение максимального количества очков\n",
    "max_value = max(scores.values())\n",
    "max_keys = {key for key, value in scores.items() if value == max_value}\n",
    "#Вывод лучшей(-их) стратегии(-й)\n",
    "for key in max_keys:\n",
    "    print(f\"The best strategy is: {key}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
